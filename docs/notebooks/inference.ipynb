{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Inference & Evaluation Pipeline\n",
    "\n",
    "This script demonstrates how to:\n",
    "1. Load trained models of different types \n",
    "2. Run inference on new data using the loaded model.\n",
    "3. Compute and plot the overall ROC curve (AUROC).\n",
    "4. Compute and plot ROC curves (and corresponding AUROC scores) per strata,\n",
    "    where each strata is defined as the composite of `tissue_type` and `imputed_labels`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import anndata as ad\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# Set matplotlib backend for Jupyter notebooks\n",
    "%matplotlib inline\n",
    "\n",
    "project_root = Path.cwd().parent.parent\n",
    "print(f\"Project root: {project_root}\")\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "import scxpand\n",
    "\n",
    "from scxpand.data_util.data_splitter import get_patient_identifiers\n",
    "from scxpand.data_util.transforms import extract_is_expanded\n",
    "from scxpand.util.general_util import metrics_dict_to_dataframes\n",
    "from scxpand.util.plots import plot_roc_curve, plot_roc_curves_per_strata\n",
    "\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model configuration\n",
    "\n",
    "1. **Local Model**: Set `RESULTS_PATH` to use a model you trained locally (default)\n",
    "2. **Registry Model**: Set `MODEL_NAME` to use a curated pre-trained model from scXpand \n",
    "3. **Direct URL**: Set `MODEL_URL` to use any external model via direct URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set ONE of the following inference modes:\n",
    "\n",
    "# === OPTION 1: load model from local path\n",
    "# RESULTS_PATH = project_root / \"results/mlp\"\n",
    "# MODEL_NAME = None\n",
    "# MODEL_URL = None\n",
    "\n",
    "# === OPTION 2: load model from registry using the model name (choose from list_pretrained_models())\n",
    "RESULTS_PATH = None\n",
    "MODEL_NAME = \"pan_cancer_autoencoder\"\n",
    "MODEL_URL = None\n",
    "\n",
    "# === OPTION 3: load model from URL\n",
    "# RESULTS_PATH = None\n",
    "# MODEL_NAME = None\n",
    "# MODEL_URL = \"https://your-platform.com/model.zip\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data input configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose ONE of the following options:\n",
    "\n",
    "# Option 1: File-based inference (memory efficient for large datasets)\n",
    "DATA_PATH = project_root / \"data\" / \"scXpand_counts_with_expansion_for_model_08_12_2024.h5ad\"\n",
    "\n",
    "# Option 2: In-memory inference (faster for smaller datasets)\n",
    "# Uncomment and modify one of these lines, then set DATA_PATH = None:\n",
    "# adata = ad.read_h5ad(\"your_data.h5ad\")  # Load from file into memory\n",
    "# adata = your_existing_adata_object      # Use existing AnnData object\n",
    "adata = None  # Set this to your AnnData object for in-memory mode\n",
    "\n",
    "# If using in-memory mode, set DATA_PATH = None\n",
    "# DATA_PATH = None\n",
    "\n",
    "# Optional: Use subset of data for evaluation\n",
    "# If SPLIT_PATH is not None, only the patient IDs in the subset will be used for evaluation\n",
    "SPLIT_PATH = project_root / \"results\" / \"optuna_studies\" / \"dev_patient_ids.csv\"\n",
    "# Otherwise, the full dataset will be used for evaluation:\n",
    "# SPLIT_PATH = None  # Use full dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference parameters\n",
    "BATCH_SIZE = 2048\n",
    "NUM_WORKERS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set save path (if None, results will not be saved)\n",
    "SAVE_PATH = None\n",
    "# SAVE_PATH = project_root / \"results/inference_results\"\n",
    "\n",
    "if SAVE_PATH:\n",
    "    SAVE_PATH.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "The notebook automatically detects your data input mode:\n",
    "- **File mode**: If `DATA_PATH` is provided and `adata` is None\n",
    "- **Memory mode**: If `adata` is provided and `DATA_PATH` is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data based on configuration\n",
    "if adata is None and DATA_PATH is not None:\n",
    "    # File-based mode: load as backed for memory efficiency\n",
    "    print(f\"Loading data from file: {DATA_PATH}\")\n",
    "    adata = ad.read_h5ad(DATA_PATH, backed=\"r\")\n",
    "    print(f\"Loaded {adata.n_obs} cells, {adata.n_vars} genes (file-backed)\")\n",
    "elif adata is not None:\n",
    "    # Memory mode: adata already provided in configuration\n",
    "    print(f\"Using provided AnnData object: {adata.n_obs} cells, {adata.n_vars} genes\")\n",
    "else:\n",
    "    raise ValueError(\"Must provide either DATA_PATH or adata in configuration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get subset of data for evaluation (if specified)\n",
    "\n",
    "if SPLIT_PATH:\n",
    "    with open(SPLIT_PATH) as f:\n",
    "        dev_patient_ids = [line.strip() for line in f]\n",
    "    patient_identifiers = get_patient_identifiers(obs_df=adata.obs)\n",
    "    eval_row_inds = np.where(patient_identifiers.isin(dev_patient_ids))[0]\n",
    "else:\n",
    "    eval_row_inds = np.arange(len(adata))\n",
    "\n",
    "n_cells_eval = len(eval_row_inds)\n",
    "assert n_cells_eval > 0, \"No cells found for evaluation\"\n",
    "print(f\"Evaluating on {n_cells_eval} cells ({n_cells_eval / len(adata) * 100:.2f}% of total)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference using the unified scXpand API\n",
    "\n",
    "# Use the unified inference function - automatically handles all model types!\n",
    "results = scxpand.run_inference(\n",
    "    data_path=DATA_PATH,\n",
    "    adata=adata,\n",
    "    model_path=RESULTS_PATH,\n",
    "    model_name=MODEL_NAME,\n",
    "    model_url=MODEL_URL,\n",
    "    save_path=SAVE_PATH,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    eval_row_inds=eval_row_inds,\n",
    ")\n",
    "\n",
    "# Extract results\n",
    "y_pred_prob = results.predictions\n",
    "\n",
    "print(f\"Generated predictions for {len(y_pred_prob)} cells\")\n",
    "print(f\"Example predictions: {y_pred_prob[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if results.has_metrics:\n",
    "    overall_df, category_df = metrics_dict_to_dataframes(results.metrics, precision=4)\n",
    "\n",
    "    # Display overall metrics\n",
    "    if overall_df is not None:\n",
    "        print(\"Overall Metrics:\")\n",
    "        display(overall_df)\n",
    "\n",
    "    # Display category-specific metrics\n",
    "    if category_df is not None:\n",
    "        print(\"\\nCategory-Specific Metrics:\")\n",
    "        display(category_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if results.has_metrics:\n",
    "    eval_obs = adata[eval_row_inds].obs\n",
    "    y_true = extract_is_expanded(eval_obs)\n",
    "\n",
    "    overall_auroc = plot_roc_curve(\n",
    "        labels=y_true,\n",
    "        probs_pred=y_pred_prob,\n",
    "        show_plot=True,\n",
    "        plot_save_dir=SAVE_PATH,\n",
    "        plot_name=\"roc_curve_overall\",\n",
    "        title=\"ROC Curve (all cells)\",\n",
    "    )\n",
    "    print(f\"Overall AUROC (all cells): {overall_auroc:.5f}. Plot saved to {SAVE_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per-Strata AUROC Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-strata evaluation\n",
    "if results.has_metrics:\n",
    "    strata_cols = [\"tissue_type\", \"imputed_labels\"]\n",
    "    strata_df = eval_obs[strata_cols]\n",
    "    strata = strata_df.astype(str).agg(\" - \".join, axis=1)\n",
    "    strata.index = eval_obs.index\n",
    "\n",
    "    unique_strata = strata.unique()\n",
    "    print(f\"Unique strata found: {unique_strata}\")\n",
    "\n",
    "    print(f\"Harmonic Average AUROC per Strata: {results.get_harmonic_avg_auroc():.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if results.has_metrics:\n",
    "    auroc_per_strata = plot_roc_curves_per_strata(\n",
    "        y_true=y_true,\n",
    "        y_pred_prob=y_pred_prob,\n",
    "        obs_df=eval_obs,\n",
    "        strata_columns=strata_cols,\n",
    "        show_plot=True,\n",
    "        plot_save_dir=SAVE_PATH,\n",
    "        max_cols=2,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def save_predictions(\n",
    "    predictions: np.ndarray,\n",
    "    adata: ad.AnnData,\n",
    "    save_path: Path,\n",
    ") -> None:\n",
    "    if not SAVE_PATH:\n",
    "        return\n",
    "    pred_column_name = \"expansion_probability\"\n",
    "    predictions_df = pd.DataFrame({\"cell_id\": adata.obs.index, pred_column_name: predictions})\n",
    "    csv_path = save_path / \"predictions.csv\"\n",
    "    try:\n",
    "        predictions_df.to_csv(csv_path, index=False)\n",
    "        print(f\"Saved predictions to {csv_path}\")\n",
    "    except Exception:\n",
    "        print(f\"Failed to save predictions to {csv_path}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "# Note: We need to create a subset of adata that matches the predictions\n",
    "# Since predictions are already subset to eval_row_inds, we need matching adata subset\n",
    "eval_adata_subset = adata[eval_row_inds]\n",
    "save_predictions(predictions=y_pred_prob, adata=eval_adata_subset, save_path=SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up: close file if it was opened in backed mode\n",
    "if hasattr(adata, \"isbacked\") and adata.isbacked:\n",
    "    adata.file.close()\n",
    "    print(\"Closed backed AnnData file\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
